{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-18-d3c269eed4f5>, line 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-d3c269eed4f5>\"\u001b[0;36m, line \u001b[0;32m40\u001b[0m\n\u001b[0;31m    print(\"COMPUTE doc \" + str(id))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import porter\n",
    "from TextRepresenter import PorterStemmer\n",
    "from ParserCACM import ParserCACM\n",
    "import pickle as pkl\n",
    "\n",
    "\n",
    "class Index():\n",
    "\tdef __init__(self, name, parser, textRepresenter, dir):\n",
    "\t\tself.name = name\n",
    "\t\tself.docFrom = {}\n",
    "\t\tself.parser = parser\n",
    "\t\tself.textRepresenter = textRepresenter\n",
    "\t\tself.index = {}\n",
    "\t\tself.index_inverse = {}\n",
    "\t\tself.dir = dir\n",
    "\t\tself.index_file = dir + 'index_file'\n",
    "\t\tself.index_file_inverse = dir + 'index_inverse_file'\n",
    "\t\tself.doc_Id = []\n",
    "\n",
    "\tdef indexation(self, filename):\n",
    "\t\tself.parser.initFile(filename)\n",
    "\n",
    "\t\t#Fichier d'index\n",
    "\t\tindex_file = open(self.index_file, 'wb')\n",
    "\t\tindex_inverse_file = open(self.index_file_inverse, 'wb')\n",
    "\t\tdoc_file = open(filename , 'r')\n",
    "\n",
    "\n",
    "\t\t# Premiere passe\n",
    "\t\tdoc = self.parser.nextDocument()\n",
    "\t\tdoc_source_place = 0\n",
    "\t\tdoc_place = 0\n",
    "\t\tstem_place = 0\n",
    "        i=0\n",
    "        print (\"STEP COMPUTE\")\n",
    "        while (doc != None)&(i<100):\n",
    "            i+=1\n",
    "            id = doc.identifier\n",
    "            self.doc_Id.append(id)\n",
    "            print(\"COMPUTE doc \" + str(id))\n",
    "            self.docFrom[id] = (filename, doc_source_place, len(doc.text))\n",
    "            doc_source_place += len(doc.text)\n",
    "            # Index normal, on \"reserve\" la place\n",
    "            bow = self.textRepresenter.getTextRepresentation(doc.text)\n",
    "            str_bow = self._dict_to_file(bow)\n",
    "            byte_size = len(str_bow)\n",
    "            self.index[id] = (doc_place, byte_size)\n",
    "            doc_place += byte_size\n",
    "            #Pour chaque stem, on le rajoute en tant que cle\n",
    "            for i in bow.keys():\n",
    "                if i not in self.index_inverse.keys():\n",
    "                    # Si il n'existe pas, on initialise sa position et sa longueur a 0\n",
    "                    self.index_inverse[i] = (0, 0)\n",
    "                #On met a jour sa longueur, si il existe, on addition sa longueur\n",
    "                self.index_inverse[i] = (0, self.index_inverse[i][1] + len(self._line_to_file(id, bow[i])))\n",
    "            doc = self.parser.nextDocument()\n",
    "\n",
    "        #A ce stade, les position sont a 0, on met a jour a partir de la long precedente\n",
    "            for stem in self.index_inverse.keys():\n",
    "            self.index_inverse[stem] = (stem_place, self.index_inverse[stem][1])\n",
    "            stem_place += self.index_inverse[stem][1]\n",
    "\n",
    "\n",
    "        print(\"STEP WRITE\")\n",
    "        # Seconde passe\n",
    "        self.parser.initFile(filename)\n",
    "\t\tdoc = self.parser.nextDocument()\n",
    "\t\tstem_place = {}\n",
    "        i=0\n",
    "\t\twhile (doc != None)&(i<100):\n",
    "            i+=1\n",
    "            id = doc.identifier\n",
    "            print(\"WRITE doc \" + str(id))\n",
    "\t\t\t# Index normal\n",
    "\t\t\tbow = self.textRepresenter.getTextRepresentation(doc.text)\n",
    "\t\t\t#Pour chaque doc, on met l'offset a sa position et on ecrit les \"stem | tf\"\n",
    "\t\t\tindex_file.seek(self.index[id][0])\n",
    "\t\t\tindex_file.write(self._dict_to_file(bow))\n",
    "\n",
    "\t\t\t#Index inverse\n",
    "\t\t\t#On prend la position dans index_reverse...\n",
    "\t\t\tfor stem in bow.keys():\n",
    "\t\t\t\tif stem not in stem_place.keys():\n",
    "\t\t\t\t\tstem_place[stem] = self.index_inverse[stem][0]\n",
    "\t\t\t\t#L'offset est place a la position du stem et on ecrit \"id_doc | tf\"\n",
    "\t\t\t\tindex_inverse_file.seek(stem_place[stem])\n",
    "\t\t\t\tindex_inverse_file.write(self._line_to_file(id, bow[stem]))\n",
    "\t\t\t\t#Pour le meme stem, la position est additionee par sa longueur\n",
    "\t\t\t\tstem_place[stem] = stem_place[stem] + len(self._line_to_file(id, bow[stem]))\n",
    "\t\t\tdoc = self.parser.nextDocument()\n",
    "\n",
    "\t\tdoc_file.flush()\n",
    "\t\tdoc_file.close()\n",
    "\t\tindex_file.flush()\n",
    "\t\tindex_inverse_file.flush()\n",
    "\t\tindex_file.close()\n",
    "\t\tindex_inverse_file.close()\n",
    "\n",
    "\tdef getTfsForDoc(self, id_doc):\n",
    "\t\tindex_file = open(self.index_file , 'r')\n",
    "\t\tindex_file.seek(self.index[id_doc][0])\n",
    "\t\tstem_tf = index_file.read(self.index[id_doc][1])\n",
    "\t\tindex_file.flush()\n",
    "\t\tindex_file.close()\n",
    "\t\treturn stem_tf\n",
    "\n",
    "\tdef getTfsForStem(self, stem):\n",
    "\t\tindex_file_inverse = open(self.index_file_inverse, 'r')\n",
    "\t\tindex_file_inverse.seek(self.index_inverse[stem][0])\n",
    "\t\tdoc_tf = index_file_inverse.read(self.index_inverse[stem][1])\n",
    "\t\tindex_file_inverse.flush()\n",
    "\t\tindex_file_inverse.close()\n",
    "\t\treturn doc_tf\n",
    "\n",
    "\tdef getStrDoc(self, id_doc):\n",
    "\t\tf = open(self.docFrom[id_doc][0], 'r')\n",
    "\t\tf.seek(self.docFrom[id_doc][1])\n",
    "\t\tdoc = f.read(self.docFrom[id_doc][2])\n",
    "\t\tf.flush()\n",
    "\t\tf.close()\n",
    "\t\treturn doc\n",
    "\n",
    "\n",
    "\tdef _dict_to_file(self, dict):\n",
    "\t\treturn ''.join([self._line_to_file(i, dict[i]) for i in dict.keys()])\n",
    "\n",
    "\tdef _line_to_file(self, i, v):\n",
    "\t\treturn str(i) + '|' + str(v) + ' '\n",
    "\n",
    "\n",
    "tr = PorterStemmer()\n",
    "parser = ParserCACM()\n",
    "index = Index(\"test\", parser, tr, \"/home/gozuslayer/Dac/Dac/RI/TP/RI/cacm\")\n",
    "\n",
    "rep = index.getTfsForDoc('99')\n",
    "text = index.getStrDoc('99')\n",
    "stem = index.getTfsForStem('system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
