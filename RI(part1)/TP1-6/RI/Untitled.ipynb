{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import porter\n",
    "from TextRepresenter import PorterStemmer\n",
    "from ParserCACM import ParserCACM\n",
    "import pickle as pkl\n",
    "\n",
    "\n",
    "class Index():\n",
    "\tdef __init__(self, name, parser, textRepresenter, dir):\n",
    "\t\tself.name = name\n",
    "\t\tself.docFrom = {}\n",
    "\t\tself.parser = parser\n",
    "\t\tself.textRepresenter = textRepresenter\n",
    "\t\tself.index = {}\n",
    "\t\tself.index_inverse = {}\n",
    "\t\tself.dir = dir\n",
    "\t\tself.index_file = dir + 'index_file'\n",
    "\t\tself.index_file_inverse = dir + 'index_inverse_file'\n",
    "\n",
    "\tdef indexation(self, filename):\n",
    "\t\tself.parser.initFile(filename)\n",
    "\n",
    "\t\t#Fichier d'index\n",
    "\t\tindex_file = open(self.index_file, 'wb')\n",
    "\t\tindex_inverse_file = open(self.index_file_inverse, 'wb')\n",
    "\t\tdoc_file = open(filename , 'r')\n",
    "\n",
    "\n",
    "\t\t# Premiere passe\n",
    "\t\tdoc = self.parser.nextDocument()\n",
    "\t\tdoc_source_place = 0\n",
    "\t\tdoc_place = 0\n",
    "\t\tstem_place = 0\n",
    "\t\tprint (\"STEP COMPUTE\")\n",
    "\t\twhile (doc != None):\n",
    "\t\t\tid = doc.identifier\n",
    "\t\t\tif int(id) > 100:\n",
    "\t\t\t\tbreak\n",
    "\t\t\tprint(\"COMPUTE doc \" + str(id))\n",
    "\t\t\tself.docFrom[id] = (filename, doc_source_place, len(doc.text))\n",
    "\t\t\tdoc_source_place += len(doc.text)\n",
    "\t\t\t# Index normal, on \"reserve\" la place\n",
    "\t\t\tbow = self.textRepresenter.getTextRepresentation(doc.text)\n",
    "\t\t\tstr_bow = self._dict_to_file(bow)\n",
    "\t\t\tbyte_size = len(str_bow)\n",
    "\t\t\tself.index[id] = (doc_place, byte_size)\n",
    "\t\t\tdoc_place += byte_size\n",
    "\t\t\t#Pour chaque stem, on le rajoute en tant que cle\n",
    "\t\t\tfor i in bow.keys():\n",
    "\t\t\t\tif i not in self.index_inverse.keys():\n",
    "\t\t\t\t\t# Si il n'existe pas, on initialise sa position et sa longueur a 0\n",
    "\t\t\t\t\tself.index_inverse[i] = (0, 0)\n",
    "\t\t\t\t#On met a jour sa longueur, si il existe, on addition sa longueur\n",
    "\t\t\t\tself.index_inverse[i] = (0, self.index_inverse[i][1] + len(self._line_to_file(id, bow[i])))\n",
    "\t\t\tdoc = self.parser.nextDocument()\n",
    "\n",
    "\t\t#A ce stade, les position sont a 0, on met a jour a partir de la long precedente\n",
    "\t\tfor stem in self.index_inverse.keys():\n",
    "\t\t\tself.index_inverse[stem] = (stem_place, self.index_inverse[stem][1])\n",
    "\t\t\tstem_place += self.index_inverse[stem][1]\n",
    "\n",
    "\n",
    "\t\tprint(\"STEP WRITE\")\n",
    "\t\t# Seconde passe\n",
    "\t\tself.parser.initFile(filename)\n",
    "\t\tdoc = self.parser.nextDocument()\n",
    "\t\tstem_place = {}\n",
    "\t\twhile (doc != None):\n",
    "\t\t\tid = doc.identifier\n",
    "\t\t\tif int(id) > 100:\n",
    "\t\t\t\tbreak\n",
    "\t\t\tprint(\"WRITE doc \" + str(id))\n",
    "\t\t\t# Index normal\n",
    "\t\t\tbow = self.textRepresenter.getTextRepresentation(doc.text)\n",
    "\t\t\t#Pour chaque doc, on met l'offset a sa position et on ecrit les \"stem | tf\"\n",
    "\t\t\tindex_file.seek(self.index[id][0])\n",
    "\t\t\tindex_file.write(self._dict_to_file(bow))\n",
    "\n",
    "\t\t\t#Index inverse\n",
    "\t\t\t#On prend la position dans index_reverse...\n",
    "\t\t\tfor stem in bow.keys():\n",
    "\t\t\t\tif stem not in stem_place.keys():\n",
    "\t\t\t\t\tstem_place[stem] = self.index_inverse[stem][0]\n",
    "\t\t\t\t#L'offset est place a la position du stem et on ecrit \"id_doc | tf\"\n",
    "\t\t\t\tindex_inverse_file.seek(stem_place[stem])\n",
    "\t\t\t\tindex_inverse_file.write(self._line_to_file(id, bow[stem]))\n",
    "\t\t\t\t#Pour le meme stem, la position est additionee par sa longueur\n",
    "\t\t\t\tstem_place[stem] = stem_place[stem] + len(self._line_to_file(id, bow[stem]))\n",
    "\t\t\tdoc = self.parser.nextDocument()\n",
    "        \n",
    "\t\tdoc_file.flush()\n",
    "\t\tdoc_file.close()\n",
    "\t\tindex_file.flush()\n",
    "\t\tindex_inverse_file.flush()\n",
    "\t\tindex_file.close()\n",
    "\t\tindex_inverse_file.close()\n",
    "\n",
    "\tdef getTfsForDoc(self, id_doc):\n",
    "\t\tindex_file = open(self.index_file , 'r')\n",
    "\t\tindex_file.seek(self.index[id_doc][0])\n",
    "\t\tstem_tf = index_file.read(self.index[id_doc][1])\n",
    "\t\tindex_file.flush()\n",
    "\t\tindex_file.close()\n",
    "\t\treturn stem_tf\n",
    "\n",
    "\tdef getTfsForStem(self, stem):\n",
    "\t\tindex_file_inverse = open(self.index_file_inverse, 'r')\n",
    "\t\tindex_file_inverse.seek(self.index_inverse[stem][0])\n",
    "\t\tdoc_tf = index_file_inverse.read(self.index_inverse[stem][1])\n",
    "\t\tindex_file_inverse.flush()\n",
    "\t\tindex_file_inverse.close()\n",
    "\t\treturn doc_tf\n",
    "\n",
    "\tdef getStrDoc(self, id_doc):\n",
    "\t\tf = open(self.docFrom[id_doc][0], 'r')\n",
    "\t\tf.seek(self.docFrom[id_doc][1])\n",
    "\t\tdoc = f.read(self.docFrom[id_doc][2])\n",
    "\t\tf.flush()\n",
    "\t\tf.close()\n",
    "\t\treturn doc\n",
    "\n",
    "\n",
    "\tdef _dict_to_file(self, dict):\n",
    "\t\treturn ''.join([self._line_to_file(i, dict[i]) for i in dict.keys()])\n",
    "\n",
    "\tdef _line_to_file(self, i, v):\n",
    "\t\treturn str(i) + '|' + str(v) + ' '\n",
    "\n",
    "\n",
    "tr = PorterStemmer()\n",
    "parser = ParserCACM()\n",
    "index = Index(\"test\", parser, tr, \"C:\\Users\\Jeremy\\Documents\\RI\\out_cacm\\\\\")\n",
    "index.indexation(\"C:\\Users\\Jeremy\\Documents\\RI\\cacm\\cacm.txt\")\n",
    "rep = index.getTfsForDoc('99')\n",
    "text = index.getStrDoc('99')\n",
    "stem = index.getTfsForStem('system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "index_file=open('cacmtest_index','rb')\n",
    "a = index_file.read()\n",
    "score = {1:1,2:2,3:3}\n",
    "with open('donnees','wrb') as file:\n",
    "    mypickler = pkl.Pickler(file)\n",
    "    mypickler.dump(score)\n",
    "    mypickler.dump(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1, 2: 2, 3: 3} A|1 Internat|1 Samelson|1 Preliminari|1 K|1 J|1 Perli|1 Algebraic|1 Report|1 Languag|1 Digit|1 Repeat|1 Comput|1 I|1 Root|1 Extraction|1 Sugai|1 Subtract|1 Depart|1 Matrix|1 Friedman|1 M|1 Program|1 Scheme|1 Techniqu|1 D|1 Glossari|1 Programm|1 Comput|1 Terminolog|1 Engineer|1 Squar|1 G|1 Approxim|1 Two|1 W|1 Wadei|1 Root|1 \n"
     ]
    }
   ],
   "source": [
    "with open('donnees','rb') as file:\n",
    "    mypickler = pkl.Unpickler(file)\n",
    "    a = mypickler.load()\n",
    "    b = mypickler.load()\n",
    "    print a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pickle.Unpickler instance at 0x7f31144a7ab8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypickler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', 13], ['10', 47], ['10-bit', 47], ['1023', 47], ['1957', 85], ['1957-II', 83], ['1957-III', 58], ['2', 10], ['2', 83], ['220', 35], ['256', 65], ['40', 95], ['4800', 62], ['5000', 62], ['64', 47], ['64', 47], ['650', 32], ['650', 35], [\"650's\", 68], ['650-Part', 49], ['650-Part', 68], ['704', 30], ['704', 95], ['709', 60], ['=', 47], ['A', 0], ['A', 10], ['A', 10], ['A', 13], ['A', 13], ['A', 15], ['A', 16], ['A', 19], ['A', 20], ['A', 24], ['A', 25], ['A', 32], ['A', 32], ['A', 34], ['A', 35], ['A', 37], ['A', 38], ['A', 39], ['A', 39], ['A', 41], ['A', 42], ['A', 45], ['A', 47], ['A', 47], ['A', 53], ['A', 57], ['A', 64], ['A', 65], ['A', 67], ['A', 68], ['A', 72], ['A', 73], ['A', 77], ['A', 77], ['A', 79], ['A', 81], ['A', 82], ['A', 86], ['A', 88], ['A', 90], ['A', 91], ['A', 91], ['A', 91], ['A', 92], ['A', 94], ['ALGOL', 37], ['ALGOL', 52], ['ALGOL', 63], ['ALGOL', 64], ['AN', 57], ['Accelerat', 19], ['Acton,', 37], ['Adams,', 17], ['Address', 78], ['Administr', 47], ['Aegerter,', 69], ['Aid', 47], ['Algebraic', 0], ['Algebraic', 20], ['Algebraic', 53], ['Algebraic', 54], ['Algebraic', 98], ['Algorithm', 28], ['Algorithm', 29], ['Alpha', 59], ['Among', 70], ['An', 19], ['An', 23], ['An', 51], ['An', 54], ['An', 67], ['An', 71], ['An', 87], ['An', 91], ['An', 93], ['An', 93], ['Analog', 95], ['Analysi', 84], ['Analyz', 29], ['Applicabl', 62], ['Applicat', 21], ['Applicat', 47], ['Applicat', 48], ['Approxim', 4], ['Arden,', 76], ['Arithmet', 16], ['Arithmet', 84], ['Arithmet', 89], ['Arithmet', 97], ['Assimil', 72], ['Astrahan,', 46], ['Automat', 17], ['Automat', 33], ['Automat', 58], ['Automat', 79], ['Automat', 83], ['Automat', 85], ['Automat', 96], ['Automat', 97], ['B', 26], ['B', 32], ['B', 35], ['B', 50], ['B', 76], ['B', 79], ['B', 97], ['Bagley,', 70], ['Bailin,', 95], ['Bemer,', 25], ['Bemer,', 34], ['Bemer,', 65], ['Bemer,', 91], ['Bessel', 26], ['Bessel', 95], ['Binari', 22], ['Binari', 32], ['Binari', 39], ['Binari', 39], ['Binari', 62], ['Binari', 75], ['Binari', 89], ['Binary-Search', 31], ['Blachman,', 66], ['Bound', 26], ['Brittenham,', 53], ['Buchholz,', 39], ['Burrough', 35], ['Busi', 48], ['Busi', 58], ['Busi', 83], ['Busi', 85], ['C', 32], ['C', 45], ['C', 48], ['C', 95], ['CA590406', 83], ['Calcul', 32], ['Calcul', 78], ['Calculat', 25], ['Call,', 11], ['Capt', 96], ['Capt', 96], ['Card', 65], ['Carr', 82], ['Carr', 84], ['Carr', 99], ['Center', 56], ['Center', 82], ['Central-European', 66], ['Chang', 10], ['Chang', 13], ['Charact', 65], ['Characterist', 77], ['Chart', 44], ['Chart', 55], ['Check', 23], ['Checklist', 91], ['Chines', 62], ['Choic', 39], ['Chow,', 74], ['Clark,', 53], ['Codd,', 45], ['Code', 17], ['Code', 47], ['Code', 65], ['Code', 97], ['Code-Nundrum', 30], ['Coeffici', 88], ['Collom', 96], ['Command', 22], ['Committe', 52], ['Commun', 10], ['Commun', 13], ['Compensat', 77], ['Compil', 60], ['Compil', 99], ['Comput', 1], ['Comput', 3], ['Comput', 5], ['Comput', 6], ['Comput', 9], ['Comput', 12], ['Comput', 18], ['Comput', 21], ['Comput', 22], ['Comput', 33], ['Comput', 34], ['Comput', 36], ['Comput', 40], ['Comput', 41], ['Comput', 43], ['Comput', 46], ['Comput', 56], ['Comput', 57], ['Comput', 62], ['Comput', 66], ['Comput', 67], ['Comput', 71], ['Comput', 79], ['Comput', 79], ['Comput', 82], ['Comput', 89], ['Comput', 92], ['Comput', 95], ['Comput', 95], ['Comput', 96], ['Computers,', 67], ['Concept', 62], ['Congress', 85], ['Consider', 45], ['Constraint', 59], ['Construct', 50], ['Construct', 69], ['Construct', 76], ['Control', 83], ['Control', 85], ['Control', 85], ['Converg', 19], ['Conversion,', 75], ['Conway,', 8], ['Conway,', 35], ['Cook,', 51], ['Corley,', 27], ['Corp', 96], ['Corrigendum', 51], ['Counter', 32], ['Critic', 79], ['Crozier,', 50], ['Curv', 14], ['Curv', 48], ['Curv', 61], ['Curv', 93], ['D', 2], ['D', 7], ['D', 11], ['D', 41], ['D', 42], ['D', 43], ['D', 60], ['D', 73], ['D', 75], ['D', 88], ['DEZU', 57], ['Data', 58], ['Data', 67], ['Data', 72], ['Data', 83], ['Data', 85], ['Decemb', 58], ['Decemb', 83], ['Decemb', 85], ['Decim', 22], ['Decim', 23], ['Decim', 39], ['Decim', 75], ['Decim', 75], ['Depart', 2], ['Department--Automat', 21], ['Design', 62], ['Detail', 67], ['Develop', 36], ['Develop', 58], ['Develop', 83], ['Develop', 85], ['Develop', 96], ['Diagram', 20], ['Diagram', 62], ['Differenti', 94], ['Digit', 1], ['Digit', 57], ['Digit', 96], ['Dijkstra,', 64], ['Discret', 89], ['Distribut', 51]] 2358\n"
     ]
    }
   ],
   "source": [
    "index[0][0]\n",
    "print index[1:300],len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Index(name,docs,stems,docFrom,parser,text_Representer):\n",
    "    def indexation(self,data):\n",
    "        self.\n",
    "        return self\n",
    "    def getTfsForDoc(self,document):\n",
    "        return stem-tf\n",
    "    def getTfsForStem(self,stem):\n",
    "        return doc-tf\n",
    "    def getStrDoc(self,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j=0\n",
    "for i in x2_text_list:\n",
    "    x2_text_list[j] = stem(i)\n",
    "    j=j+1\n",
    "print x2_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x3 = a.nextDocument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x4 = a.nextDocument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss True\n"
     ]
    }
   ],
   "source": [
    "a ='ss'\n",
    "print a,type(a) is str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
